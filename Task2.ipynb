{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1a014-7631-417c-9a0c-be00d7c0b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task 2: Deep Learning on Raw Inertial Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a5be80-0540-4698-9dd9-0f24227df180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = r\"C:\\Users\\vedant\\Downloads\\human+activity+recognition+using+smartphones\\UCI HAR Dataset\\UCI HAR Dataset\\train\"\n",
    "test_dir = r\"C:\\Users\\vedant\\Downloads\\human+activity+recognition+using+smartphones\\UCI HAR Dataset\\UCI HAR Dataset\\test\"\n",
    "\n",
    "# Load raw sensor data\n",
    "def load_raw_sensor_data(dir_path, files):\n",
    "    data = []\n",
    "    for file in files:\n",
    "        file_path = f\"{dir_path}/Inertial Signals/{file}\"\n",
    "        data.append(np.loadtxt(file_path))\n",
    "    return np.stack(data, axis=-1)  # Shape: (samples, timesteps, features)\n",
    "\n",
    "# Define signal file names\n",
    "signal_files = [\n",
    "    \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
    "    \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
    "    \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Load train and test data\n",
    "X_train_raw = load_raw_sensor_data(train_dir, [f\"{s}train.txt\" for s in signal_files])\n",
    "X_test_raw = load_raw_sensor_data(test_dir, [f\"{s}test.txt\" for s in signal_files])\n",
    "\n",
    "# Load labels\n",
    "y_train_raw = np.loadtxt(f\"{train_dir}/y_train.txt\").astype(int) - 1\n",
    "y_test_raw = np.loadtxt(f\"{test_dir}/y_test.txt\").astype(int) - 1\n",
    "\n",
    "# Convert labels to one-hot encoding \n",
    "num_classes = len(np.unique(y_train_raw))\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train_raw, num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test_raw, num_classes)\n",
    "\n",
    "# Input shape for models\n",
    "input_shape = X_train_raw.shape[1:]  # (timesteps, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295e001d-1280-4a9f-9acc-729e7c24aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedant\\Documents\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.6880 - loss: 0.7642 - val_accuracy: 0.8633 - val_loss: 0.4476\n",
      "Epoch 2/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9189 - loss: 0.2191 - val_accuracy: 0.8663 - val_loss: 0.5957\n",
      "Epoch 3/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9397 - loss: 0.1605 - val_accuracy: 0.8602 - val_loss: 0.7325\n",
      "Epoch 4/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9443 - loss: 0.1450 - val_accuracy: 0.9141 - val_loss: 0.4578\n",
      "Epoch 5/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9474 - loss: 0.1322 - val_accuracy: 0.9019 - val_loss: 0.6534\n",
      "Epoch 6/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9499 - loss: 0.1170 - val_accuracy: 0.8992 - val_loss: 0.5557\n",
      "Epoch 7/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9451 - loss: 0.1328 - val_accuracy: 0.9128 - val_loss: 0.6466\n",
      "Epoch 8/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9475 - loss: 0.1198 - val_accuracy: 0.9165 - val_loss: 0.8044\n",
      "Epoch 9/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9592 - loss: 0.1048 - val_accuracy: 0.9172 - val_loss: 0.9512\n",
      "Epoch 10/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9526 - loss: 0.1070 - val_accuracy: 0.9080 - val_loss: 0.9410\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
      "CNN Metrics: {'Accuracy': 0.9080420766881574, 'Precision': 0.9128591009609506, 'Recall': 0.9080420766881574, 'F1 Score': 0.9081549724740983}\n"
     ]
    }
   ],
   "source": [
    "# Define CNN Model\n",
    "def build_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Training\n",
    "model_cnn = build_cnn_model()\n",
    "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# evaluation\n",
    "model_cnn.fit(X_train_raw, y_train_one_hot, validation_data=(X_test_raw, y_test_one_hot), epochs=10, batch_size=32)\n",
    "\n",
    "# Prediction and calculation\n",
    "y_pred_cnn = model_cnn.predict(X_test_raw).argmax(axis=1)\n",
    "cnn_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test_raw, y_pred_cnn),\n",
    "    \"Precision\": precision_score(y_test_raw, y_pred_cnn, average='weighted'),\n",
    "    \"Recall\": recall_score(y_test_raw, y_pred_cnn, average='weighted'),\n",
    "    \"F1 Score\": f1_score(y_test_raw, y_pred_cnn, average='weighted')\n",
    "}\n",
    "\n",
    "print(\"CNN Metrics:\", cnn_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533e88a3-8b8b-4828-833f-89ddd7c03e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedant\\Documents\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5396 - loss: 1.1628 - val_accuracy: 0.8140 - val_loss: 0.6290\n",
      "Epoch 2/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8029 - loss: 0.5337 - val_accuracy: 0.8687 - val_loss: 0.4580\n",
      "Epoch 3/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8780 - loss: 0.3537 - val_accuracy: 0.8697 - val_loss: 0.4281\n",
      "Epoch 4/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8924 - loss: 0.2889 - val_accuracy: 0.8670 - val_loss: 0.4673\n",
      "Epoch 5/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9037 - loss: 0.2860 - val_accuracy: 0.8826 - val_loss: 0.3789\n",
      "Epoch 6/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9105 - loss: 0.2400 - val_accuracy: 0.8802 - val_loss: 0.5861\n",
      "Epoch 7/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9192 - loss: 0.2238 - val_accuracy: 0.8972 - val_loss: 0.3931\n",
      "Epoch 8/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9288 - loss: 0.1978 - val_accuracy: 0.9002 - val_loss: 0.3266\n",
      "Epoch 9/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9261 - loss: 0.1916 - val_accuracy: 0.8948 - val_loss: 0.4478\n",
      "Epoch 10/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9295 - loss: 0.1928 - val_accuracy: 0.9125 - val_loss: 0.4316\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "MLP Metrics: {'Accuracy': 0.9124533423820834, 'Precision': 0.9136021394329755, 'Recall': 0.9124533423820834, 'F1 Score': 0.912076392619636}\n"
     ]
    }
   ],
   "source": [
    "# Define MLP Model\n",
    "def build_mlp_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Training\n",
    "model_mlp = build_mlp_model()\n",
    "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# evaluation\n",
    "model_mlp.fit(X_train_raw, y_train_one_hot, validation_data=(X_test_raw, y_test_one_hot), epochs=10, batch_size=32)\n",
    "\n",
    "# Prediction and calculation\n",
    "y_pred_mlp = model_mlp.predict(X_test_raw).argmax(axis=1)\n",
    "mlp_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test_raw, y_pred_mlp),\n",
    "    \"Precision\": precision_score(y_test_raw, y_pred_mlp, average='weighted'),\n",
    "    \"Recall\": recall_score(y_test_raw, y_pred_mlp, average='weighted'),\n",
    "    \"F1 Score\": f1_score(y_test_raw, y_pred_mlp, average='weighted')\n",
    "}\n",
    "\n",
    "print(\"MLP Metrics:\", mlp_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d855a855-531b-481f-82b3-cc54c489fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedant\\Documents\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 169ms/step - accuracy: 0.4587 - loss: 1.2752 - val_accuracy: 0.6912 - val_loss: 0.8132\n",
      "Epoch 2/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 164ms/step - accuracy: 0.7455 - loss: 0.6369 - val_accuracy: 0.7903 - val_loss: 0.5792\n",
      "Epoch 3/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 161ms/step - accuracy: 0.8630 - loss: 0.4258 - val_accuracy: 0.8649 - val_loss: 0.4466\n",
      "Epoch 4/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 159ms/step - accuracy: 0.9243 - loss: 0.2309 - val_accuracy: 0.8599 - val_loss: 0.5207\n",
      "Epoch 5/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 162ms/step - accuracy: 0.9411 - loss: 0.1794 - val_accuracy: 0.8911 - val_loss: 0.3909\n",
      "Epoch 6/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 162ms/step - accuracy: 0.9431 - loss: 0.1716 - val_accuracy: 0.8823 - val_loss: 0.4970\n",
      "Epoch 7/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 166ms/step - accuracy: 0.9381 - loss: 0.1677 - val_accuracy: 0.8636 - val_loss: 0.4772\n",
      "Epoch 8/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 165ms/step - accuracy: 0.9404 - loss: 0.1723 - val_accuracy: 0.8426 - val_loss: 0.6822\n",
      "Epoch 9/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - accuracy: 0.9383 - loss: 0.1580 - val_accuracy: 0.8992 - val_loss: 0.3701\n",
      "Epoch 10/10\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 159ms/step - accuracy: 0.9415 - loss: 0.1507 - val_accuracy: 0.9002 - val_loss: 0.3807\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step\n",
      "LSTM Metrics: {'Accuracy': 0.9002375296912114, 'Precision': 0.9023874036561389, 'Recall': 0.9002375296912114, 'F1 Score': 0.8996065183233869}\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM Model\n",
    "def build_lstm_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Training\n",
    "model_lstm = build_lstm_model()\n",
    "model_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# evaluation\n",
    "model_lstm.fit(X_train_raw, y_train_one_hot, validation_data=(X_test_raw, y_test_one_hot), epochs=10, batch_size=32)\n",
    "\n",
    "# Prediction and calculation\n",
    "y_pred_lstm = model_lstm.predict(X_test_raw).argmax(axis=1)\n",
    "lstm_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test_raw, y_pred_lstm),\n",
    "    \"Precision\": precision_score(y_test_raw, y_pred_lstm, average='weighted'),\n",
    "    \"Recall\": recall_score(y_test_raw, y_pred_lstm, average='weighted'),\n",
    "    \"F1 Score\": f1_score(y_test_raw, y_pred_lstm, average='weighted')\n",
    "}\n",
    "\n",
    "print(\"LSTM Metrics:\", lstm_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38aa58cd-d165-4c27-9452-a2d7fd43c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model  Accuracy  Precision    Recall  F1 Score\n",
      "0   CNN  0.908042   0.912859  0.908042  0.908155\n",
      "1   MLP  0.912453   0.913602  0.912453  0.912076\n",
      "2  LSTM  0.900238   0.902387  0.900238  0.899607\n"
     ]
    }
   ],
   "source": [
    "# Comparison function\n",
    "def compare_models(cnn_metrics, mlp_metrics, lstm_metrics):\n",
    "   comparison = {\n",
    "        'Model': ['CNN', 'MLP', 'LSTM'],\n",
    "        'Accuracy': [cnn_metrics['Accuracy'], mlp_metrics['Accuracy'], lstm_metrics['Accuracy']],\n",
    "        'Precision': [cnn_metrics['Precision'], mlp_metrics['Precision'], lstm_metrics['Precision']],\n",
    "        'Recall': [cnn_metrics['Recall'], mlp_metrics['Recall'], lstm_metrics['Recall']],\n",
    "        'F1 Score': [cnn_metrics['F1 Score'], mlp_metrics['F1 Score'], lstm_metrics['F1 Score']]\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    return comparison_df\n",
    "comparison_results = compare_models(cnn_metrics, mlp_metrics, lstm_metrics)\n",
    "\n",
    "print(comparison_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d003c-5f2d-41f6-8f83-f74d6469497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Performance Summary \n",
    "\n",
    "In this task,evaluation of three deep learning models for human activity recognition were done.\n",
    "\n",
    "- MLP achieved the highest accuracy of 91.25%, along with the best precision and recall values.\n",
    "\n",
    "- CNN followed closely with an accuracy of 90.80% along with decent precision,recall value and F1 Score.\n",
    "\n",
    "- LSTM had the lowest accuracy at 90.02% with lowest precision,recall value and F1 Score.\n",
    "\n",
    "### Conclusion:\n",
    "Based on the results, MLP stands out as the most effective model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b24d0-2296-4f1a-b9dd-d816c62a324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Performance Comparison: Task 1 (Machine Learning) vs Task 2 (Deep Learning)\n",
    "\n",
    "- Task 1 Models: Logistic Regression stands out as the best performer in the classic machine learning models, with an impressive accuracy of 95.49%, while Random Forest is a strong second.\n",
    "- Task 2 Models: MLP performed best among the deep learning models, with 91.25% accuracy, though it falls behind the logistic regression from Task 1.\n",
    "- Overall Comparison: Classic machine learning models, especially Logistic Regression and Random Forest, generally outperformed the deep learning models in terms of accuracy, precision, and recall for this human activity recognition task.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
